TASK_TYPE: inference_instructvideo_entrance
ENABLE: true
frame_lens: [16]
resolution: [256, 256]
vit_resolution: [224, 224]

embedder: {
    'type': 'FrozenOpenCLIPEmbedderZero',
    'layer': 'penultimate',
    'pretrained': 'models/stable-diffusion-v/open_clip_pytorch_model.bin'
}

UNet: {
    'type': 'UNetSD_LoRA',
    'in_dim': 4,
    'dim': 320,
    'y_dim': 1024,
    'context_dim': 1024,
    'out_dim': 4,
    'dim_mult': [1, 2, 4, 4],
    'num_heads': 8,
    'head_dim': 64,
    'num_res_blocks': 2,
    'attn_scales': [1.0, 0.5, 0.25],
    'dropout': 0.1,
    'temporal_attention': True,
    'temporal_attn_times': 1,
    'use_checkpoint': True,
    'use_fps_condition': False,
    'use_sim_mask': False,
    ### For LoRA tuning
    'use_lora': True, # False, # True,
    'lora_rank': 4,
    'lora_alpha': , # In yaml, 'None' does not need to be specified. 
}

chunk_size: 4
decoder_bs: 4
temporal_offset_noise: false
temporal_offset_noise_strength: 0.1
share_noise: False

Diffusion: {
    'type': 'DiffusionDDIMReward',
    'schedule': 'linear_sd',
    'schedule_param': {
        'num_timesteps': 1000,
        'init_beta': 0.00085,
        'last_beta': 0.0120,
        'zero_terminal_snr': False,
    },
    'mean_type': 'eps',
    'loss_type': 'mse',
    'var_type': 'fixed_small',
    'rescale_timesteps': False,
    'noise_strength': 0,
}
ddim_timesteps: 50
ddim_steps: [981, 961, 941, 921, 901, 881, 861, 841, 821, 801, 781, 761, 741, 721, 701, 681, 661, 641, 621, 601, 581, 561, 541, 521, 501, 481, 461, 441, 421, 401, 381, 361, 341, 321, 301, 281, 261, 241, 221, 201, 181, 161, 141, 121, 101,  81,  61,  41,  21,   1]

webvid_dir: 'data/instructvideo/'
webvid_cap_file: 'eval/'
webvid_eval_text: 'simple_animals_2_webvid_videos_selected_eval'
webvid_test_caps: 263
webvid_dir_save: 'data/instructvideo/generated/reward_webvid_ani45_20_reg_vidldm_LoRA_TSNExp16Diffreward_Partial06_Trunc1_Check_ddim50_0620000_4A_'
infer_checkpoint: 'models/instructvideo-finetuned/ddim20_1102-18-52_non_ema_0620000.pth'

suffix: ''
seed: 8888